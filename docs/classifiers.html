<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<link rel="icon" href="imgs/favicon.ico">
<link rel="stylesheet" href="https://bootswatch.com/5/flatly/bootstrap.css">
<link rel="stylesheet" href="https://bootswatch.com/_vendor/bootstrap-icons/font/bootstrap-icons.css">
<link rel="stylesheet" href="https://bootswatch.com/_vendor/prismjs/themes/prism-okaidia.css">
<link rel="stylesheet" href="https://bootswatch.com/_assets/css/custom.min.css">

<title>Classification models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="classifiers_files/libs/clipboard/clipboard.min.js"></script>
<script src="classifiers_files/libs/quarto-html/quarto.js"></script>
<script src="classifiers_files/libs/quarto-html/popper.min.js"></script>
<script src="classifiers_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="classifiers_files/libs/quarto-html/anchor.min.js"></script>
<link href="classifiers_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="classifiers_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="classifiers_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="classifiers_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="classifiers_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

  <div class="navbar navbar-expand-lg fixed-top navbar-dark bg-primary">
    <div class="container">
      <a href="index.html" class="navbar-brand">Revelio</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle active" data-bs-toggle="dropdown" id="notebooks" href="notebooks.html">Notebooks</a>
            <div class="dropdown-menu" aria-labelledby="notebooks">
              <a class="dropdown-item text-info" href="exploratory-data-analysis.html">Exploratory Data Analysis</a>
              <a class="dropdown-item text-info" href="#">Classification models</a>
              <a class="dropdown-item" href="notebooks.html">Back to Notebooks</a>
            </div>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
        </ul>
        <ul class="navbar-nav ms-md-auto">
          <li class="nav-item">
            <a target="_blank" rel="noopener" class="nav-link" href="https://github.com/mafesan/Memoria-TFM/"><i class="bi bi-github"></i> GitHub</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full toc-left">
<div id="quarto-sidebar-toc-left fixed-top" class="sidebar toc-left" style="padding-top:100px;">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>

  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#apply-pre-processing-to-the-training-and-test-datasets" id="toc-apply-pre-processing-to-the-training-and-test-datasets" class="nav-link" data-scroll-target="#apply-pre-processing-to-the-training-and-test-datasets">Apply pre-processing to the training and test datasets</a>
  <ul class="collapse">
  <li><a href="#apply-smote-to-mitigate-the-effect-of-imbalanced-data" id="toc-apply-smote-to-mitigate-the-effect-of-imbalanced-data" class="nav-link" data-scroll-target="#apply-smote-to-mitigate-the-effect-of-imbalanced-data">Apply SMOTE to mitigate the effect of imbalanced data</a></li>
  <li><a href="#pca" id="toc-pca" class="nav-link" data-scroll-target="#pca">PCA</a></li>
  </ul></li>
  <li><a href="#study-classes-distribution-using-t-sne" id="toc-study-classes-distribution-using-t-sne" class="nav-link" data-scroll-target="#study-classes-distribution-using-t-sne">Study classes’ distribution using t-SNE</a></li>
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics">Evaluation metrics</a></li>
  <li><a href="#testing-the-classification-models" id="toc-testing-the-classification-models" class="nav-link" data-scroll-target="#testing-the-classification-models">Testing the classification models</a>
  <ul class="collapse">
  <li><a href="#gaussian-naïve-bayes" id="toc-gaussian-naïve-bayes" class="nav-link" data-scroll-target="#gaussian-naïve-bayes">Gaussian Naïve-Bayes</a></li>
  <li><a href="#support-vector-classifier" id="toc-support-vector-classifier" class="nav-link" data-scroll-target="#support-vector-classifier">Support Vector Classifier</a></li>
  <li><a href="#k-nearest-neighbors" id="toc-k-nearest-neighbors" class="nav-link" data-scroll-target="#k-nearest-neighbors">K-Nearest Neighbors</a></li>
  <li><a href="#decision-trees" id="toc-decision-trees" class="nav-link" data-scroll-target="#decision-trees">Decision Trees</a></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random forest</a></li>
  <li><a href="#xgboost-classifier" id="toc-xgboost-classifier" class="nav-link" data-scroll-target="#xgboost-classifier">XGBoost Classifier</a></li>
  </ul></li>
  <li><a href="#models-evaluation" id="toc-models-evaluation" class="nav-link" data-scroll-target="#models-evaluation">Models Evaluation</a></li>
  <li><a href="#validate-results-randon-forest-classifier" id="toc-validate-results-randon-forest-classifier" class="nav-link" data-scroll-target="#validate-results-randon-forest-classifier">Validate results: Randon Forest Classifier</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Classification models</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">




  </div>


</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In this phase, the goal is to train several classification models and test their performance against our dataset. Then, after having the results using a set of evaluation metrics we will choose the best classifier. This whole process starts with the splitting of our initial dataset into three sets (Training, Test, and Validation), following the criteria we discussed at the Exploratory Data Analysis, and then apply the pre-processing step: the transformation and selection of features (over the Training and Test datasets) and also applying SMOTE to mitigate the effect of the imbalance of the classes.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Import modules</span></span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb1-7"><a href="#cb1-7"></a></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">#Ignore warnings</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="im">import</span> warnings</span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co"># For plotting</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="im">import</span> matplotlib.patheffects <span class="im">as</span> PathEffects</span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="im">from</span> matplotlib <span class="im">import</span> offsetbox</span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co"># Pre-processing</span></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="im">from</span> imblearn.over_sampling <span class="im">import</span> SMOTE</span>
<span id="cb1-21"><a href="#cb1-21"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-22"><a href="#cb1-22"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb1-24"><a href="#cb1-24"></a></span>
<span id="cb1-25"><a href="#cb1-25"></a><span class="co"># Evaluation metrics</span></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="im">import</span> sklearn.metrics</span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> auc,<span class="op">\</span></span>
<span id="cb1-28"><a href="#cb1-28"></a>                            classification_report,<span class="op">\</span></span>
<span id="cb1-29"><a href="#cb1-29"></a>                            precision_score,<span class="op">\</span></span>
<span id="cb1-30"><a href="#cb1-30"></a>                            recall_score,<span class="op">\</span></span>
<span id="cb1-31"><a href="#cb1-31"></a>                            accuracy_score,<span class="op">\</span></span>
<span id="cb1-32"><a href="#cb1-32"></a>                            fbeta_score,<span class="op">\</span></span>
<span id="cb1-33"><a href="#cb1-33"></a>                            roc_curve,<span class="op">\</span></span>
<span id="cb1-34"><a href="#cb1-34"></a>                            roc_auc_score,<span class="op">\</span></span>
<span id="cb1-35"><a href="#cb1-35"></a>                            ConfusionMatrixDisplay,<span class="op">\</span></span>
<span id="cb1-36"><a href="#cb1-36"></a>                            plot_roc_curve,<span class="op">\</span></span>
<span id="cb1-37"><a href="#cb1-37"></a>                            plot_confusion_matrix,<span class="op">\</span></span>
<span id="cb1-38"><a href="#cb1-38"></a>                            balanced_accuracy_score</span>
<span id="cb1-39"><a href="#cb1-39"></a></span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a><span class="co"># Clssification models</span></span>
<span id="cb1-42"><a href="#cb1-42"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-44"><a href="#cb1-44"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb1-45"><a href="#cb1-45"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC, LinearSVC</span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-47"><a href="#cb1-47"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-49"><a href="#cb1-49"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-50"><a href="#cb1-50"></a></span>
<span id="cb1-51"><a href="#cb1-51"></a><span class="co">#  Feature importance</span></span>
<span id="cb1-52"><a href="#cb1-52"></a><span class="im">from</span> yellowbrick.datasets <span class="im">import</span> load_occupancy</span>
<span id="cb1-53"><a href="#cb1-53"></a><span class="im">from</span> yellowbrick.model_selection <span class="im">import</span> FeatureImportances</span>
<span id="cb1-54"><a href="#cb1-54"></a></span>
<span id="cb1-55"><a href="#cb1-55"></a><span class="co"># K-fold corss validation</span></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold, cross_validate, cross_val_score</span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> fbeta_score, make_scorer</span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a>pd.options.mode.chained_assignment <span class="op">=</span> <span class="va">None</span>  <span class="co"># default='warn'</span></span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a><span class="co"># Yellowbrick</span></span>
<span id="cb1-62"><a href="#cb1-62"></a><span class="im">from</span> yellowbrick.classifier <span class="im">import</span> PrecisionRecallCurve,<span class="op">\</span></span>
<span id="cb1-63"><a href="#cb1-63"></a>                                   classification_report,<span class="op">\</span></span>
<span id="cb1-64"><a href="#cb1-64"></a>                                   confusion_matrix,<span class="op">\</span></span>
<span id="cb1-65"><a href="#cb1-65"></a>                                   roc_auc,<span class="op">\</span></span>
<span id="cb1-66"><a href="#cb1-66"></a>                                   precision_recall_curve,<span class="op">\</span></span>
<span id="cb1-67"><a href="#cb1-67"></a>                                   class_prediction_error,<span class="op">\</span></span>
<span id="cb1-68"><a href="#cb1-68"></a>                                   discrimination_threshold</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Import Git dataset</span></span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a>data_path <span class="op">=</span> <span class="st">'./datasets'</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>df_git <span class="op">=</span> pd.read_json(<span class="st">'</span><span class="sc">{}</span><span class="st">/df_git.json'</span>.<span class="bu">format</span>(data_path), orient<span class="op">=</span><span class="st">'records'</span>, lines<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co"># Separate target variable</span></span>
<span id="cb2-7"><a href="#cb2-7"></a>y_git <span class="op">=</span> df_git.pop(<span class="st">'author_bot'</span>)</span>
<span id="cb2-8"><a href="#cb2-8"></a></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co">## Re-generate "Train", "Test" and "Validation" data sub-sets</span></span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co"># Divide the Dataset into 60% training and 40% test + validation</span></span>
<span id="cb2-12"><a href="#cb2-12"></a>X_train_git_og, X_test_tmp_git,<span class="op">\</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>y_train_git, y_test_tmp_git <span class="op">=</span> train_test_split(df_git, y_git, test_size<span class="op">=</span><span class="fl">0.4</span>,</span>
<span id="cb2-14"><a href="#cb2-14"></a>                                               random_state<span class="op">=</span><span class="dv">22</span>, stratify<span class="op">=</span>y_git)</span>
<span id="cb2-15"><a href="#cb2-15"></a></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="co"># From 40% of the original dataset, 25% is for test and 15% is for validation</span></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co"># This means we have to split the test+validation set in a 62,5%/37,5% ratio</span></span>
<span id="cb2-18"><a href="#cb2-18"></a></span>
<span id="cb2-19"><a href="#cb2-19"></a>X_test_git_og, X_val_git_og,<span class="op">\</span></span>
<span id="cb2-20"><a href="#cb2-20"></a>y_test_git, y_val_git <span class="op">=</span> train_test_split(X_test_tmp_git, y_test_tmp_git,</span>
<span id="cb2-21"><a href="#cb2-21"></a>                                         test_size<span class="op">=</span><span class="fl">0.375</span>, random_state<span class="op">=</span><span class="dv">22</span>,</span>
<span id="cb2-22"><a href="#cb2-22"></a>                                         stratify<span class="op">=</span>y_test_tmp_git)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="apply-pre-processing-to-the-training-and-test-datasets" class="level2">
<h2 class="anchored" data-anchor-id="apply-pre-processing-to-the-training-and-test-datasets">Apply pre-processing to the training and test datasets</h2>
<p>After performing the Exploratory Data Analysis, we have a clear process to consider which transformation apply to the variables and which are the ones we are selecting.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">def</span> log10(x):</span>
<span id="cb3-2"><a href="#cb3-2"></a>    <span class="cf">return</span> np.log(x)</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="kw">def</span> shifted_log10(x):</span>
<span id="cb3-5"><a href="#cb3-5"></a>    <span class="cf">return</span> np.log(<span class="dv">1</span> <span class="op">+</span> x)</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a>heuristic_terms <span class="op">=</span> [<span class="st">'auto'</span>, <span class="st">'bot'</span>, <span class="st">'build'</span>, <span class="st">'cd'</span>, <span class="st">'ci'</span>, <span class="st">'code'</span>, <span class="st">'commit'</span>, <span class="st">'copy'</span>,</span>
<span id="cb3-8"><a href="#cb3-8"></a>                   <span class="st">'dependency'</span>, <span class="st">'fix'</span>, <span class="st">'integration'</span>, <span class="st">'issue'</span>, <span class="st">'merge'</span>, <span class="st">'patrol'</span>,</span>
<span id="cb3-9"><a href="#cb3-9"></a>                   <span class="st">'pr'</span>, <span class="st">'pull'</span>, <span class="st">'release'</span>, <span class="st">'request'</span>, <span class="st">'review'</span>, <span class="st">'sync'</span>, <span class="st">'template'</span>,</span>
<span id="cb3-10"><a href="#cb3-10"></a>                   <span class="st">'tool'</span>, <span class="st">'travis'</span>]</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a>terms_l1 <span class="op">=</span> [<span class="st">'bot'</span>, <span class="st">'dependency'</span>, <span class="st">'fix'</span>, <span class="st">'merge'</span>, <span class="st">'integration'</span>]</span>
<span id="cb3-13"><a href="#cb3-13"></a>terms_l2 <span class="op">=</span> [<span class="st">'build'</span>, <span class="st">'travis'</span>, <span class="st">'copy'</span>, <span class="st">'template'</span>, <span class="st">'sync'</span>,  <span class="st">'auto'</span>,</span>
<span id="cb3-14"><a href="#cb3-14"></a>            <span class="st">'release'</span>, <span class="st">'review'</span>, <span class="st">'tool'</span>, <span class="st">'issue'</span>, <span class="st">'request'</span>, <span class="st">'commit'</span>]</span>
<span id="cb3-15"><a href="#cb3-15"></a>terms_l3 <span class="op">=</span> [<span class="st">'ci'</span>, <span class="st">'cd'</span>, <span class="st">'pr'</span>, <span class="st">'code'</span>, <span class="st">'patrol'</span>, <span class="st">'pull'</span>]</span>
<span id="cb3-16"><a href="#cb3-16"></a></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="kw">def</span> compute_terms_score(x, terms):</span>
<span id="cb3-18"><a href="#cb3-18"></a>    score <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-19"><a href="#cb3-19"></a>    n_l1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>    n_l2 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-21"><a href="#cb3-21"></a>    n_l3 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>    <span class="cf">for</span> term <span class="kw">in</span> terms:</span>
<span id="cb3-23"><a href="#cb3-23"></a>        <span class="cf">if</span> term.lower() <span class="kw">in</span> x.lower():</span>
<span id="cb3-24"><a href="#cb3-24"></a>            <span class="cf">if</span> term <span class="kw">in</span> terms_l1:</span>
<span id="cb3-25"><a href="#cb3-25"></a>                n_l1 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-26"><a href="#cb3-26"></a>            <span class="cf">elif</span> term <span class="kw">in</span> terms_l2:</span>
<span id="cb3-27"><a href="#cb3-27"></a>                n_l2 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-28"><a href="#cb3-28"></a>            <span class="cf">elif</span> term <span class="kw">in</span> terms_l3:</span>
<span id="cb3-29"><a href="#cb3-29"></a>                n_l3 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-30"><a href="#cb3-30"></a>    score <span class="op">=</span> <span class="dv">60</span><span class="op">*</span>n_l1 <span class="op">+</span> <span class="dv">30</span><span class="op">*</span>n_l2 <span class="op">+</span> <span class="dv">10</span><span class="op">*</span>n_l3</span>
<span id="cb3-31"><a href="#cb3-31"></a></span>
<span id="cb3-32"><a href="#cb3-32"></a>    <span class="cf">return</span> score</span>
<span id="cb3-33"><a href="#cb3-33"></a></span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="kw">def</span> preprocess_git_df(git_df):</span>
<span id="cb3-35"><a href="#cb3-35"></a>    new_git_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb3-36"><a href="#cb3-36"></a>    new_git_df[<span class="st">"git__log_num_commits"</span>] <span class="op">=</span> git_df[<span class="st">"git__num_commits"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: log10(x))</span>
<span id="cb3-37"><a href="#cb3-37"></a>    new_git_df[<span class="st">"git__log_num_merge_commits"</span>] <span class="op">=</span> git_df[<span class="st">"git__num_merge_commits"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-38"><a href="#cb3-38"></a>    new_git_df[<span class="st">"git__log_num_weekend_commits"</span>] <span class="op">=</span> git_df[<span class="st">"git__num_weekend_commits"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-39"><a href="#cb3-39"></a>    new_git_df[<span class="st">"git__log_num_signed_commits"</span>] <span class="op">=</span> git_df[<span class="st">"git__num_signed_commits"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-40"><a href="#cb3-40"></a>    </span>
<span id="cb3-41"><a href="#cb3-41"></a>    new_git_df[<span class="st">"git__log_num_repos"</span>] <span class="op">=</span> git_df[<span class="st">"git__num_repos"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: log10(x))</span>
<span id="cb3-42"><a href="#cb3-42"></a>    new_git_df[<span class="st">"git__log_median_files"</span>] <span class="op">=</span> git_df[<span class="st">"git__median_files"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-43"><a href="#cb3-43"></a>    new_git_df[<span class="st">"git__log_iqr_files"</span>] <span class="op">=</span> git_df[<span class="st">"git__iqr_files"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-44"><a href="#cb3-44"></a>    </span>
<span id="cb3-45"><a href="#cb3-45"></a>    new_git_df[<span class="st">"git__log_median_lines_added"</span>] <span class="op">=</span> git_df[<span class="st">"git__median_lines_added"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-46"><a href="#cb3-46"></a>    new_git_df[<span class="st">"git__log_median_lines_removed"</span>] <span class="op">=</span> git_df[<span class="st">"git__median_lines_removed"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-47"><a href="#cb3-47"></a>    new_git_df[<span class="st">"git__log_median_len_commit_message"</span>] <span class="op">=</span> git_df[<span class="st">"git__median_len_commit_message"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-48"><a href="#cb3-48"></a>    new_git_df[<span class="st">"git__log_iqr_len_words_commit_message"</span>] <span class="op">=</span> git_df[<span class="st">"git__iqr_len_words_commit_message"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: shifted_log10(x))</span>
<span id="cb3-49"><a href="#cb3-49"></a>    </span>
<span id="cb3-50"><a href="#cb3-50"></a>    new_git_df[<span class="st">'terms_score'</span>] <span class="op">=</span> git_df[<span class="st">'author_name'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: compute_terms_score(x, heuristic_terms))</span>
<span id="cb3-51"><a href="#cb3-51"></a>    </span>
<span id="cb3-52"><a href="#cb3-52"></a>    <span class="cf">return</span> new_git_df</span>
<span id="cb3-53"><a href="#cb3-53"></a></span>
<span id="cb3-54"><a href="#cb3-54"></a>X_train_git <span class="op">=</span> preprocess_git_df(X_train_git_og)</span>
<span id="cb3-55"><a href="#cb3-55"></a>X_test_git <span class="op">=</span> preprocess_git_df(X_test_git_og)</span>
<span id="cb3-56"><a href="#cb3-56"></a>X_train_git.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>git__log_num_commits</th>
      <th>git__log_num_merge_commits</th>
      <th>git__log_num_weekend_commits</th>
      <th>git__log_num_signed_commits</th>
      <th>git__log_num_repos</th>
      <th>git__log_median_files</th>
      <th>git__log_iqr_files</th>
      <th>git__log_median_lines_added</th>
      <th>git__log_median_lines_removed</th>
      <th>git__log_median_len_commit_message</th>
      <th>git__log_iqr_len_words_commit_message</th>
      <th>terms_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2352</th>
      <td>7.080868</td>
      <td>2.302585</td>
      <td>5.986452</td>
      <td>0.0</td>
      <td>5.087596</td>
      <td>0.693147</td>
      <td>1.098612</td>
      <td>1.791759</td>
      <td>1.098612</td>
      <td>5.129899</td>
      <td>2.564949</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2985</th>
      <td>6.453625</td>
      <td>5.497168</td>
      <td>5.442418</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>4.158883</td>
      <td>2.197225</td>
      <td>0</td>
    </tr>
    <tr>
      <th>390</th>
      <td>2.772589</td>
      <td>0.000000</td>
      <td>1.098612</td>
      <td>0.0</td>
      <td>1.791759</td>
      <td>0.693147</td>
      <td>0.810930</td>
      <td>1.504077</td>
      <td>1.098612</td>
      <td>5.117994</td>
      <td>2.197225</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1164</th>
      <td>3.737670</td>
      <td>1.098612</td>
      <td>1.945910</td>
      <td>0.0</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>1.098612</td>
      <td>0.693147</td>
      <td>3.891820</td>
      <td>2.014903</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2935</th>
      <td>2.484907</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.693147</td>
      <td>1.386294</td>
      <td>0.916291</td>
      <td>3.465736</td>
      <td>0.693147</td>
      <td>5.249652</td>
      <td>2.442347</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="apply-smote-to-mitigate-the-effect-of-imbalanced-data" class="level3">
<h3 class="anchored" data-anchor-id="apply-smote-to-mitigate-the-effect-of-imbalanced-data">Apply SMOTE to mitigate the effect of imbalanced data</h3>
<p>We already commented in the Exploratory Data Analysis the fact that one of the main challenges of this project is the imbalance in the target class we are aiming to detect. This context was taken into account when splitting the main dataset into the training, test, and validation tests, but it needs another processing stage before they feed the different classification models.</p>
<p><strong>SMOTE</strong> is based on an algorithm generating new samples considering the k-nearest neighbors from each original sample from the <strong>training set</strong>. Each newly generated sample is interpolated between the original sample and one of the nearest neighbors; with a random component <span class="math inline">\(\lambda\)</span>, which takes value in the range <span class="math inline">\([0, 1]\)</span>.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>smt <span class="op">=</span> SMOTE(random_state<span class="op">=</span><span class="dv">22</span>)</span>
<span id="cb4-2"><a href="#cb4-2"></a>X_train_git_SMOTE, y_train_git_SMOTE <span class="op">=</span> smt.fit_resample(X_train_git, y_train_git)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-scrolled="true" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">7</span>))</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a>sns.histplot(data<span class="op">=</span>y_train_git.replace({<span class="dv">0</span>: <span class="st">'False'</span>, <span class="dv">1</span>: <span class="st">'True'</span>}), stat<span class="op">=</span><span class="st">'count'</span>, kde<span class="op">=</span><span class="va">False</span>, color<span class="op">=</span><span class="st">"skyblue"</span>, ax<span class="op">=</span>axs[<span class="dv">0</span>])</span>
<span id="cb5-4"><a href="#cb5-4"></a>sns.histplot(data<span class="op">=</span>y_train_git_SMOTE.replace({<span class="dv">0</span>: <span class="st">'False'</span>, <span class="dv">1</span>: <span class="st">'True'</span>}), stat<span class="op">=</span><span class="st">'count'</span>, kde<span class="op">=</span><span class="va">False</span>, discrete<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">"teal"</span>, ax<span class="op">=</span>axs[<span class="dv">1</span>])</span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="pca" class="level3">
<h3 class="anchored" data-anchor-id="pca">PCA</h3>
<p>We applied PCA (Principal Component Analysis} to discover if there was a combination of features that would suit as input for the classification model, but we discarded it as the results indicated that one component accumulated most of the percentage of variance explained.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">22</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a>principalComponents <span class="op">=</span> pca.fit_transform(X_train_git_SMOTE)</span>
<span id="cb6-3"><a href="#cb6-3"></a>trainDf <span class="op">=</span> pd.DataFrame(data<span class="op">=</span>principalComponents)</span>
<span id="cb6-4"><a href="#cb6-4"></a></span>
<span id="cb6-5"><a href="#cb6-5"></a>variance_ratio <span class="op">=</span> <span class="bu">list</span>(pca.explained_variance_ratio_)</span>
<span id="cb6-6"><a href="#cb6-6"></a>count <span class="op">=</span> <span class="dv">0</span> <span class="co"># in case list is empty</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="cf">for</span> count, var <span class="kw">in</span> <span class="bu">enumerate</span>(variance_ratio, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb6-8"><a href="#cb6-8"></a>    <span class="bu">print</span>(<span class="st">'Var. </span><span class="sc">{}</span><span class="st">: </span><span class="ch">\t</span><span class="st">Explained Variance ratio: </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(count,</span>
<span id="cb6-9"><a href="#cb6-9"></a>                                                           <span class="bu">round</span>(var, <span class="dv">3</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Var. 1:     Explained Variance ratio: 0.983
Var. 2:     Explained Variance ratio: 0.011
Var. 3:     Explained Variance ratio: 0.002</code></pre>
</div>
</div>
</section>
</section>
<section id="study-classes-distribution-using-t-sne" class="level2">
<h2 class="anchored" data-anchor-id="study-classes-distribution-using-t-sne">Study classes’ distribution using t-SNE</h2>
<p>Here, the objective is to show how the samples from the Training set were distributed using the t-SNE algorithm, a nonlinear dimensionality reduction technique. This way we could convert our high-dimensional dataset into a two-dimensional one, preserving the distance between the samples in the new dimensional space. The following figures show the redimensioned Training dataset before and applying SMOTE, respectively: In the first image, we can observe very few occurrences of positive Bot accounts, and heavily mixed among the rest of the samples from the other class; while in the second image we can observe a much clearer distinction between the two classes, after the synthetic samples generated by SMOTE. Apart from the interesting pattern these samples are forming, we infer that there should be a classification model capable of separating both classes.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb8-2"><a href="#cb8-2"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">'white'</span>, context<span class="op">=</span><span class="st">'notebook'</span>, rc<span class="op">=</span>{<span class="st">'figure.figsize'</span>:(<span class="dv">14</span>,<span class="dv">10</span>)})</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a></span>
<span id="cb8-6"><a href="#cb8-6"></a>tsne <span class="op">=</span> TSNE(random_state <span class="op">=</span> <span class="dv">22</span>, n_components<span class="op">=</span><span class="dv">2</span>,verbose<span class="op">=</span><span class="dv">0</span>, perplexity<span class="op">=</span><span class="dv">40</span>, n_iter<span class="op">=</span><span class="dv">300</span>).fit_transform(X_train_git)</span>
<span id="cb8-7"><a href="#cb8-7"></a>plt.scatter(tsne[:, <span class="dv">0</span>], tsne[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">5</span>, c<span class="op">=</span>y_train_git, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb8-8"><a href="#cb8-8"></a>plt.gca().set_aspect(<span class="st">'equal'</span>, <span class="st">'datalim'</span>)</span>
<span id="cb8-9"><a href="#cb8-9"></a>plt.colorbar(boundaries<span class="op">=</span>np.arange(<span class="dv">3</span>)<span class="op">-</span><span class="fl">0.5</span>).set_ticks(np.arange(<span class="dv">2</span>))</span>
<span id="cb8-10"><a href="#cb8-10"></a>plt.title(<span class="st">'Visualizing Training dataset through t-SNE'</span>, fontsize<span class="op">=</span><span class="dv">24</span>)<span class="op">;</span></span>
<span id="cb8-11"><a href="#cb8-11"></a></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="co"># plt.savefig('data-tsne.png', dpi=600, transparent=True)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>standardized_data_SMOTE <span class="op">=</span> StandardScaler().fit_transform(X_train_git_SMOTE)</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a>tsne_SMOTE <span class="op">=</span> TSNE(random_state <span class="op">=</span> <span class="dv">22</span>, n_components<span class="op">=</span><span class="dv">2</span>,verbose<span class="op">=</span><span class="dv">0</span>, perplexity<span class="op">=</span><span class="dv">40</span>, n_iter<span class="op">=</span><span class="dv">300</span>).fit_transform(X_train_git_SMOTE)</span>
<span id="cb9-4"><a href="#cb9-4"></a></span>
<span id="cb9-5"><a href="#cb9-5"></a>plt.scatter(tsne_SMOTE[:, <span class="dv">0</span>], tsne_SMOTE[:, <span class="dv">1</span>], s<span class="op">=</span> <span class="dv">5</span>, c<span class="op">=</span>y_train_git_SMOTE, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a>plt.gca().set_aspect(<span class="st">'equal'</span>, <span class="st">'datalim'</span>)</span>
<span id="cb9-7"><a href="#cb9-7"></a>plt.colorbar(boundaries<span class="op">=</span>np.arange(<span class="dv">3</span>)<span class="op">-</span><span class="fl">0.5</span>).set_ticks(np.arange(<span class="dv">2</span>))</span>
<span id="cb9-8"><a href="#cb9-8"></a>plt.title(<span class="st">'Visualizing Training dataset through t-SNE w/SMOTE'</span>, fontsize<span class="op">=</span><span class="dv">24</span>)<span class="op">;</span></span>
<span id="cb9-9"><a href="#cb9-9"></a></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="co"># plt.savefig('data-tsne-smote.png', dpi=600, transparent=True)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metrics">Evaluation metrics</h2>
<p>We need to use a set of metrics that help us to evaluate the performance of the different classification models. The main method to compare the results from the different models is a <strong>confusion matrix</strong>, which displays the number of elements that have and have not been identified correctly.</p>
<p>Looking at the possible values we can obtain, it is worth mentioning that not all the misclassified cases affect our use case in the same way: having <strong>False Negatives</strong> is worse than having <strong>False Positives</strong>. This means it is more important to classify as many bot accounts as possible (and not mistake any of them for a human) rather than classifying a human as a bot when it is not the case. In the first case, missing a bot account among the plethora of contributors in a community could mean that potentially this bot account remains hidden (and hardly going to be identified); while in the latter, this wrong recommendation could be just ignored.</p>
<p>This links directly to the definition of two basic metrics: <strong>precision</strong> and <strong>recall</strong>. As it is defined in <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics">Scikit-learn’s documentation page</a>, an intuitive definition of precision is the ability of the classifier not to label as positive a sample that is negative, and recall is the ability of the classifier to find all the positive samples.</p>
<p>Although it is common to use the <strong>F1-score</strong> as an evaluation metric for classification models, this score is considering that the recall and the precision are equally important. This is why the decision was to use a <strong>F-beta</strong> score with <span class="math inline">\(\beta = 2\)</span>, to penalize those classification models with a greater number of <strong>False Negatives</strong>.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="kw">def</span> print_model_report(model, X_train, y_train, X_test, y_test):</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a>    model_name <span class="op">=</span> <span class="bu">type</span>(model).<span class="va">__name__</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>    </span>
<span id="cb10-5"><a href="#cb10-5"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb10-6"><a href="#cb10-6"></a>    confusion_matrix(model, X_train, y_train, X_test, y_test)</span>
<span id="cb10-7"><a href="#cb10-7"></a></span>
<span id="cb10-8"><a href="#cb10-8"></a>    y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb10-9"><a href="#cb10-9"></a>    f2_score <span class="op">=</span> <span class="bu">round</span>(fbeta_score(y_test, y_pred, beta<span class="op">=</span><span class="dv">2</span>), <span class="dv">3</span>)</span>
<span id="cb10-10"><a href="#cb10-10"></a>    precision <span class="op">=</span> <span class="bu">round</span>(precision_score(y_test, y_pred), <span class="dv">3</span>)</span>
<span id="cb10-11"><a href="#cb10-11"></a>    recall <span class="op">=</span> <span class="bu">round</span>(recall_score(y_test, y_pred), <span class="dv">3</span>)</span>
<span id="cb10-12"><a href="#cb10-12"></a>    </span>
<span id="cb10-13"><a href="#cb10-13"></a>    <span class="cf">return</span> precision, recall, f2_score</span>
<span id="cb10-14"><a href="#cb10-14"></a></span>
<span id="cb10-15"><a href="#cb10-15"></a></span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="kw">def</span> add_score_to_df(scores_dataframe, model_name, model_subset, results):</span>
<span id="cb10-17"><a href="#cb10-17"></a>    precision <span class="op">=</span> results[<span class="dv">0</span>]</span>
<span id="cb10-18"><a href="#cb10-18"></a>    recall <span class="op">=</span> results[<span class="dv">1</span>]</span>
<span id="cb10-19"><a href="#cb10-19"></a>    f2_score <span class="op">=</span> results[<span class="dv">2</span>]</span>
<span id="cb10-20"><a href="#cb10-20"></a>    new_row <span class="op">=</span> pd.Series({<span class="st">'model_subset'</span>: model_subset,</span>
<span id="cb10-21"><a href="#cb10-21"></a>                         <span class="st">'model_name'</span>: model_name,</span>
<span id="cb10-22"><a href="#cb10-22"></a>                         <span class="st">'precision_score'</span>: <span class="bu">round</span>(precision, <span class="dv">3</span>),</span>
<span id="cb10-23"><a href="#cb10-23"></a>                         <span class="st">'recall_score'</span>: <span class="bu">round</span>(recall, <span class="dv">3</span>),</span>
<span id="cb10-24"><a href="#cb10-24"></a>                         <span class="st">'f2_score'</span>: <span class="bu">round</span>(f2_score, <span class="dv">3</span>)})</span>
<span id="cb10-25"><a href="#cb10-25"></a>    <span class="cf">return</span> pd.concat([df_scores, new_row.to_frame().T], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-26"><a href="#cb10-26"></a></span>
<span id="cb10-27"><a href="#cb10-27"></a></span>
<span id="cb10-28"><a href="#cb10-28"></a><span class="co"># Initialize DF including all scores</span></span>
<span id="cb10-29"><a href="#cb10-29"></a>df_scores <span class="op">=</span> pd.DataFrame()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="testing-the-classification-models" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-classification-models">Testing the classification models</h2>
<p>The proposed classifiers were trained and then tested, adjusting the specific hyper-parameters for each model until finding the best scoring for each of them.</p>
<section id="gaussian-naïve-bayes" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-naïve-bayes">Gaussian Naïve-Bayes</h3>
<p><strong>Naïve-Bayes</strong> supervised-learning algorithms are based on Bayes’ theorem. They belong to the Probability-based learning family, and their approach is to use estimations of likelihoods to determine the most likely predictions that should be made and review them later, based on the available data and also extra evidence whenever it becomes available.</p>
<p><em>Naïve-Bayes</em> classifiers are especially useful for problems with many input variables, categorical input variables with a vast number of possible values, and text classification. Among the advantages of using these classification models are their simplicity to apply (generally, no parameters to be adjusted) and their resistance to over-fitting.</p>
<p>The selected classifier was the <strong>Gaussian Naïve-Bayes</strong> algorithm</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Gaussian Naive-Bayes</span></span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a>gnb <span class="op">=</span> GaussianNB().fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb11-4"><a href="#cb11-4"></a>y_pred_gnb <span class="op">=</span> gnb.predict(X_test_git)</span>
<span id="cb11-5"><a href="#cb11-5"></a></span>
<span id="cb11-6"><a href="#cb11-6"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(gnb, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb11-7"><a href="#cb11-7"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb11-8"><a href="#cb11-8"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'Gaussian Naive-Bayes'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="co"># Show prettified results</span></span>
<span id="cb11-11"><a href="#cb11-11"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb11-12"><a href="#cb11-12"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb11-13"><a href="#cb11-13"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb11-14"><a href="#cb11-14"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.417</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.136</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.857</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>plt.figure()</span>
<span id="cb12-2"><a href="#cb12-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Test - Gaussian Naïve-Bayes"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb12-4"><a href="#cb12-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(gnb, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb12-7"><a href="#cb12-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb12-8"><a href="#cb12-8"></a>visualizer.score(X_test_git, y_test_git)</span>
<span id="cb12-9"><a href="#cb12-9"></a></span>
<span id="cb12-10"><a href="#cb12-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="support-vector-classifier" class="level3">
<h3 class="anchored" data-anchor-id="support-vector-classifier">Support Vector Classifier</h3>
<p>The <strong>support vector classifier</strong> is based on the possibility of constructing a hyperplane that separates the hyperplane training observations perfectly according to their class labels. Once this hyperplane exists, the ideal scenario is that a test observation is assigned to a class depending on which side of the hyperplane it is located.</p>
<p>Nonetheless, observations that belong to two classes are not necessarily separable by a hyperplane. In fact, even if a separating hyper- plane does exist, then there are instances in which a classifier based on a separating hyperplane might not be desirable. A classifier based on a separating hyperplane will necessarily perfectly classify all of the training observations; this can lead to sensitivity to individual observations and implies that it may have overfit the training data.</p>
<p>The support vector classifier does exactly this. Rather than seeking the largest possible margin so that every observation is not only on the correct side of the hyperplane but also on the correct side of the margin, we instead allow some observations to be on the incorrect side of the margin, or even the incorrect side of the hyperplane.</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># SVC</span></span>
<span id="cb13-2"><a href="#cb13-2"></a></span>
<span id="cb13-3"><a href="#cb13-3"></a>lsvc <span class="op">=</span> LinearSVC(random_state<span class="op">=</span><span class="dv">22</span>)</span>
<span id="cb13-4"><a href="#cb13-4"></a></span>
<span id="cb13-5"><a href="#cb13-5"></a>lsvc.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb13-6"><a href="#cb13-6"></a></span>
<span id="cb13-7"><a href="#cb13-7"></a>y_pred_lsvc <span class="op">=</span> lsvc.predict(X_test_git)</span>
<span id="cb13-8"><a href="#cb13-8"></a></span>
<span id="cb13-9"><a href="#cb13-9"></a>precision, recall, f2_score <span class="op">=</span>  print_model_report(lsvc, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb13-10"><a href="#cb13-10"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb13-11"><a href="#cb13-11"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'LinearSVC'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb13-12"><a href="#cb13-12"></a></span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="co"># Show prettified results</span></span>
<span id="cb13-14"><a href="#cb13-14"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb13-15"><a href="#cb13-15"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb13-16"><a href="#cb13-16"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb13-17"><a href="#cb13-17"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.429</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.143</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.857</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve-1" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve-1">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>plt.figure()</span>
<span id="cb14-2"><a href="#cb14-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Test - LinearSVC"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb14-3"><a href="#cb14-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb14-4"><a href="#cb14-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb14-5"><a href="#cb14-5"></a></span>
<span id="cb14-6"><a href="#cb14-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(lsvc, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb14-7"><a href="#cb14-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb14-8"><a href="#cb14-8"></a>visualizer.score(X_test_git, y_test_git)</span>
<span id="cb14-9"><a href="#cb14-9"></a></span>
<span id="cb14-10"><a href="#cb14-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="k-nearest-neighbors" class="level3">
<h3 class="anchored" data-anchor-id="k-nearest-neighbors">K-Nearest Neighbors</h3>
<p><strong>K-Nearest Neighbors</strong> is a similarity-based classification model whose main idea is to compute the classification from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest “k” (integer number) neighbors of the point.</p>
<p>Note that this algorithm uses the whole training dataset for making the predictions, and aside from other classification models, there are no specific assumptions that should be made concerning the data. One of the main setbacks is the fact that this algorithm is affected by noise, which implies this parameter “k” needs to be selected carefully, particularly when working with imbalanced datasets.</p>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Knn</span></span>
<span id="cb15-2"><a href="#cb15-2"></a></span>
<span id="cb15-3"><a href="#cb15-3"></a>knn <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">115</span>)</span>
<span id="cb15-4"><a href="#cb15-4"></a>knn.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb15-5"><a href="#cb15-5"></a></span>
<span id="cb15-6"><a href="#cb15-6"></a>y_pred_knn <span class="op">=</span> knn.predict(X_test_git)</span>
<span id="cb15-7"><a href="#cb15-7"></a></span>
<span id="cb15-8"><a href="#cb15-8"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(knn, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb15-9"><a href="#cb15-9"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb15-10"><a href="#cb15-10"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'KNN'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb15-11"><a href="#cb15-11"></a></span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="co"># Show prettified results</span></span>
<span id="cb15-13"><a href="#cb15-13"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb15-14"><a href="#cb15-14"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb15-15"><a href="#cb15-15"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb15-16"><a href="#cb15-16"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="14">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.638</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.316</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.857</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve-2" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve-2">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>plt.figure()</span>
<span id="cb16-2"><a href="#cb16-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Test - KNN"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb16-3"><a href="#cb16-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb16-4"><a href="#cb16-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb16-5"><a href="#cb16-5"></a></span>
<span id="cb16-6"><a href="#cb16-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(knn, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb16-7"><a href="#cb16-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb16-8"><a href="#cb16-8"></a>visualizer.score(X_test_git, y_test_git)</span>
<span id="cb16-9"><a href="#cb16-9"></a></span>
<span id="cb16-10"><a href="#cb16-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="decision-trees" class="level3">
<h3 class="anchored" data-anchor-id="decision-trees">Decision Trees</h3>
<p>The <strong>Decision Trees</strong> (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a set of if-else decision rules.</p>
<p>Providing a more academic definition, a classification tree predicts that each observation belongs to the most commonly occurring class of training observations in the region to which it belongs. In interpreting the results of a classification tree, we are often interested not only in the class prediction corresponding to a particular terminal node region, but also in the class proportions among the training observations that fall into that region.</p>
<p>We use recursive binary splitting to grow a classification tree. Since we plan to assign an observation in a given region to the most commonly occurring class of training observations in that region, the classification rror rate is simply the fraction of the training observations in that region that do not belong to the most common class. When building a classification tree, either the Gini index or the entropy is typically used to evaluate the quality of a particular split, since these two approaches are more sensitive to node purity than the classification error rate. Any of these three approaches might be used when pruning the tree, but the classification error rate is preferable if the prediction accuracy of the final pruned tree is the goal.</p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># criterion='gini'</span></span>
<span id="cb17-2"><a href="#cb17-2"></a></span>
<span id="cb17-3"><a href="#cb17-3"></a>dt <span class="op">=</span> DecisionTreeClassifier(random_state<span class="op">=</span><span class="dv">22</span>, max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb17-4"><a href="#cb17-4"></a>dt.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb17-5"><a href="#cb17-5"></a></span>
<span id="cb17-6"><a href="#cb17-6"></a>y_pred_dt <span class="op">=</span> dt.predict(X_test_git)</span>
<span id="cb17-7"><a href="#cb17-7"></a></span>
<span id="cb17-8"><a href="#cb17-8"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(dt, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb17-9"><a href="#cb17-9"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb17-10"><a href="#cb17-10"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'Decision Tree'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb17-11"><a href="#cb17-11"></a></span>
<span id="cb17-12"><a href="#cb17-12"></a><span class="co"># Show prettified results</span></span>
<span id="cb17-13"><a href="#cb17-13"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb17-14"><a href="#cb17-14"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb17-15"><a href="#cb17-15"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb17-16"><a href="#cb17-16"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="16">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.610</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.385</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.714</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve-3" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve-3">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>plt.figure()</span>
<span id="cb18-2"><a href="#cb18-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Test - Decision Tree"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb18-3"><a href="#cb18-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-4"><a href="#cb18-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-5"><a href="#cb18-5"></a></span>
<span id="cb18-6"><a href="#cb18-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(dt, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb18-7"><a href="#cb18-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb18-8"><a href="#cb18-8"></a>visualizer.score(X_test_git, y_test_git)</span>
<span id="cb18-9"><a href="#cb18-9"></a></span>
<span id="cb18-10"><a href="#cb18-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="represent-decision-tree" class="level4">
<h4 class="anchored" data-anchor-id="represent-decision-tree">Represent decision tree</h4>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="kw">def</span> shorten_name(col_name):</span>
<span id="cb19-2"><a href="#cb19-2"></a>    <span class="cf">if</span> <span class="st">'git__log_'</span> <span class="kw">in</span> col_name:</span>
<span id="cb19-3"><a href="#cb19-3"></a>        col_name <span class="op">=</span> col_name.replace(<span class="st">'git__log_'</span>, <span class="st">''</span>)</span>
<span id="cb19-4"><a href="#cb19-4"></a>    <span class="cf">return</span> col_name</span>
<span id="cb19-5"><a href="#cb19-5"></a></span>
<span id="cb19-6"><a href="#cb19-6"></a>list_cols <span class="op">=</span> <span class="bu">list</span>(X_train_git_SMOTE.columns)</span>
<span id="cb19-7"><a href="#cb19-7"></a>list_cols <span class="op">=</span> [shorten_name(var_name) <span class="cf">for</span> var_name <span class="kw">in</span> list_cols]</span>
<span id="cb19-8"><a href="#cb19-8"></a>list_cols</span>
<span id="cb19-9"><a href="#cb19-9"></a></span>
<span id="cb19-10"><a href="#cb19-10"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">60</span>,<span class="dv">30</span>))</span>
<span id="cb19-11"><a href="#cb19-11"></a>tree.plot_tree(dt, feature_names<span class="op">=</span>list_cols,  </span>
<span id="cb19-12"><a href="#cb19-12"></a>                   class_names<span class="op">=</span>[<span class="st">'Human'</span>, <span class="st">'Bot'</span>],</span>
<span id="cb19-13"><a href="#cb19-13"></a>                   filled<span class="op">=</span><span class="va">True</span>, fontsize<span class="op">=</span><span class="dv">28</span>)</span>
<span id="cb19-14"><a href="#cb19-14"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="random-forest" class="level3">
<h3 class="anchored" data-anchor-id="random-forest">Random forest</h3>
<p>We have tested the Decision Trees algorithm. Let’s have a lookt at some of its pros and cons.</p>
<p>Some of the main advantages of this algorithm are:</p>
<ul>
<li>It is simple to understand and interpret. Trees can be visualized: if a given situation is observable, the explanation for the condition is easily explained by boolean logic.</li>
<li>Requires little data preparation. Other techniques often require data normalization, dummy variables need to be created and blank values to be removed.</li>
<li>Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.</li>
</ul>
<p>The most remarkable disadvantages are:</p>
<ul>
<li>DTs can create over-complex trees that do not generalize the data well (over-fitting).</li>
<li>They can be unstable because small variations in the data might result in a completely different tree being generated.</li>
<li>Decision-tree learners create biased trees if some classes dominate. In our case, this effect would be mitigated because we applied SMOTE to balance both classes.</li>
</ul>
<p>Regarding the two first disadvantages, both can be addressed by using an ensemble model taking many decision trees. This is where the <strong>Random Forest (RF) classifier</strong> comes into play: it builds a number of decision trees on bootstrapped training samples. When building these decision trees, each time a split in a tree is considered, a random sample of <span class="math inline">\(m\)</span> predictors is chosen as split candidates from the full set of <span class="math inline">\(p\)</span> predictors. The split is allowed to use only one of those <span class="math inline">\(m\)</span> predictors. A fresh sample of <span class="math inline">\(\sqrt{m}\)</span> predictors is taken at each split, and typically we choose <span class="math inline">\(m \approx p\)</span>—that is, the number of predictors considered at each split is approximately equal to the square root of the total number of predictors.</p>
<p>Then, the prediction of the ensemble is computed as the averaged prediction of these individual classifiers, improving the predictive accuracy and preventing over-fitting.</p>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># Random forest: hyperparameters</span></span>
<span id="cb20-2"><a href="#cb20-2"></a></span>
<span id="cb20-3"><a href="#cb20-3"></a>rf_adj <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">300</span>, criterion<span class="op">=</span><span class="st">'gini'</span>, random_state<span class="op">=</span><span class="dv">22</span>, max_depth<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb20-4"><a href="#cb20-4"></a>rf_adj.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb20-5"><a href="#cb20-5"></a></span>
<span id="cb20-6"><a href="#cb20-6"></a>y_pred_rf_adj <span class="op">=</span> rf_adj.predict(X_test_git)</span>
<span id="cb20-7"><a href="#cb20-7"></a></span>
<span id="cb20-8"><a href="#cb20-8"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(rf_adj, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb20-9"><a href="#cb20-9"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb20-10"><a href="#cb20-10"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'Random Forest'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb20-11"><a href="#cb20-11"></a></span>
<span id="cb20-12"><a href="#cb20-12"></a><span class="co"># Show prettified results</span></span>
<span id="cb20-13"><a href="#cb20-13"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb20-14"><a href="#cb20-14"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb20-15"><a href="#cb20-15"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb20-16"><a href="#cb20-16"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="19">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.811</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.667</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.857</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve-4" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve-4">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>plt.figure()</span>
<span id="cb21-2"><a href="#cb21-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Test - Random Forest"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb21-3"><a href="#cb21-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb21-4"><a href="#cb21-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb21-5"><a href="#cb21-5"></a></span>
<span id="cb21-6"><a href="#cb21-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(rf_adj, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb21-7"><a href="#cb21-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb21-8"><a href="#cb21-8"></a>visualizer.score(X_test_git, y_test_git)</span>
<span id="cb21-9"><a href="#cb21-9"></a></span>
<span id="cb21-10"><a href="#cb21-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="feature-importance" class="level4">
<h4 class="anchored" data-anchor-id="feature-importance">Feature importance</h4>
<div class="cell" data-scrolled="true" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>viz <span class="op">=</span> FeatureImportances(rf_adj, xlabel<span class="op">=</span><span class="st">'Relative importance (coefficient)'</span>, relative<span class="op">=</span><span class="va">False</span>, colormap<span class="op">=</span><span class="st">'yellowbrick'</span>)</span>
<span id="cb22-2"><a href="#cb22-2"></a>viz.fit(X_test_git, y_test_git)</span>
<span id="cb22-3"><a href="#cb22-3"></a>viz.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="plot-some-trees-composing-the-random-forest" class="level4">
<h4 class="anchored" data-anchor-id="plot-some-trees-composing-the-random-forest">Plot some trees composing the random forest</h4>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># Plot a couple of the trees composing the random forest</span></span>
<span id="cb23-2"><a href="#cb23-2"></a></span>
<span id="cb23-3"><a href="#cb23-3"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">60</span>,<span class="dv">30</span>))</span>
<span id="cb23-4"><a href="#cb23-4"></a>tree.plot_tree(rf_adj[<span class="dv">22</span>], feature_names<span class="op">=</span>list_cols,  </span>
<span id="cb23-5"><a href="#cb23-5"></a>               class_names<span class="op">=</span>[<span class="st">'Human'</span>, <span class="st">'Bot'</span>],</span>
<span id="cb23-6"><a href="#cb23-6"></a>               filled<span class="op">=</span><span class="va">True</span>, fontsize<span class="op">=</span><span class="dv">28</span>)</span>
<span id="cb23-7"><a href="#cb23-7"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">60</span>,<span class="dv">30</span>))</span>
<span id="cb24-2"><a href="#cb24-2"></a>tree.plot_tree(rf_adj[<span class="dv">23</span>], feature_names<span class="op">=</span>list_cols,  </span>
<span id="cb24-3"><a href="#cb24-3"></a>               class_names<span class="op">=</span>[<span class="st">'Human'</span>, <span class="st">'Bot'</span>],</span>
<span id="cb24-4"><a href="#cb24-4"></a>               filled<span class="op">=</span><span class="va">True</span>, fontsize<span class="op">=</span><span class="dv">28</span>)</span>
<span id="cb24-5"><a href="#cb24-5"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="xgboost-classifier" class="level3">
<h3 class="anchored" data-anchor-id="xgboost-classifier">XGBoost Classifier</h3>
<p>XGBoost is an ensemble model which uses decision trees as base learners. XGBoost uses CART trees (Classification and Regression trees), with scores on whether an observation belongs to a class or not. When this process reaches the max depth of the tree, the algorithm converts the scores into categories assigning a threshold value.</p>
<div class="cell" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a>xgb_adj <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span><span class="dv">150</span>, max_depth<span class="op">=</span><span class="dv">4</span>, booster<span class="op">=</span><span class="st">'gbtree'</span>, objective<span class="op">=</span><span class="st">'binary:logistic'</span>, seed<span class="op">=</span><span class="dv">22</span>)<span class="op">;</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>xgb_adj.fit(X_train_git_SMOTE, y_train_git_SMOTE)<span class="op">;</span></span>
<span id="cb25-3"><a href="#cb25-3"></a></span>
<span id="cb25-4"><a href="#cb25-4"></a>y_pred_xgb_adj <span class="op">=</span> xgb_adj.predict(X_test_git)<span class="op">;</span></span>
<span id="cb25-5"><a href="#cb25-5"></a></span>
<span id="cb25-6"><a href="#cb25-6"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(xgb_adj, X_train_git_SMOTE, y_train_git_SMOTE, X_test_git, y_test_git)</span>
<span id="cb25-7"><a href="#cb25-7"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb25-8"><a href="#cb25-8"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'XGBoost'</span>, <span class="st">'Test'</span>, results)</span>
<span id="cb25-9"><a href="#cb25-9"></a></span>
<span id="cb25-10"><a href="#cb25-10"></a><span class="co"># Show prettified results</span></span>
<span id="cb25-11"><a href="#cb25-11"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb25-12"><a href="#cb25-12"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb25-13"><a href="#cb25-13"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb25-14"><a href="#cb25-14"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[21:26:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-25-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="24">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.541</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.444</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.571</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="models-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="models-evaluation">Models Evaluation</h2>
<p>The results from the tested classifiers are summarized in the following table:</p>
<div class="cell" data-execution_count="25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a>df_scores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="25">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>model_subset</th>
      <th>model_name</th>
      <th>precision_score</th>
      <th>recall_score</th>
      <th>f2_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Test</td>
      <td>Gaussian Naive-Bayes</td>
      <td>0.136</td>
      <td>0.857</td>
      <td>0.417</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Test</td>
      <td>LinearSVC</td>
      <td>0.143</td>
      <td>0.857</td>
      <td>0.429</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Test</td>
      <td>KNN</td>
      <td>0.316</td>
      <td>0.857</td>
      <td>0.638</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Test</td>
      <td>Decision Tree</td>
      <td>0.385</td>
      <td>0.714</td>
      <td>0.61</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Test</td>
      <td>Random Forest</td>
      <td>0.667</td>
      <td>0.857</td>
      <td>0.811</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Test</td>
      <td>XGBoost</td>
      <td>0.444</td>
      <td>0.571</td>
      <td>0.541</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>The classification model with the best results was the <strong>Random Forest Classifier</strong>. These results were also tested using a 5-fold cross validation.</p>
<p>The parameters that worked best for the Random Forest Classifier were: * Number of estimators (Trees in the forest): 300. * Split criterion: Gini impurity. * Maximum depth: 4 levels.</p>
<section id="k-fold-cross-validation" class="level5">
<h5 class="anchored" data-anchor-id="k-fold-cross-validation">K-fold cross validation</h5>
<div class="cell" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Define K-Fold Cross Validation</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>cv <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">22</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-3"><a href="#cb28-3"></a></span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="co"># Define scoring function</span></span>
<span id="cb28-5"><a href="#cb28-5"></a></span>
<span id="cb28-6"><a href="#cb28-6"></a>f_two_scorer <span class="op">=</span> make_scorer(fbeta_score, beta<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb28-7"><a href="#cb28-7"></a></span>
<span id="cb28-8"><a href="#cb28-8"></a>scoring_dict <span class="op">=</span> {</span>
<span id="cb28-9"><a href="#cb28-9"></a>    <span class="st">'f2_score'</span>: f_two_scorer</span>
<span id="cb28-10"><a href="#cb28-10"></a>}</span>
<span id="cb28-11"><a href="#cb28-11"></a></span>
<span id="cb28-12"><a href="#cb28-12"></a><span class="co"># Evaluate model</span></span>
<span id="cb28-13"><a href="#cb28-13"></a>scores <span class="op">=</span> cross_validate(rf_adj, X_train_git_SMOTE, y_train_git_SMOTE, scoring<span class="op">=</span>scoring_dict, cv<span class="op">=</span>cv, n_jobs<span class="op">=-</span><span class="dv">1</span>, return_train_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-14"><a href="#cb28-14"></a></span>
<span id="cb28-15"><a href="#cb28-15"></a><span class="co"># Report Performance</span></span>
<span id="cb28-16"><a href="#cb28-16"></a>kfold_df <span class="op">=</span> pd.DataFrame.from_dict(scores)</span>
<span id="cb28-17"><a href="#cb28-17"></a>kfold_df.index.name <span class="op">=</span> <span class="st">'Fold'</span></span>
<span id="cb28-18"><a href="#cb28-18"></a>kfold_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="26">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_f2_score</th>
      <th>train_f2_score</th>
    </tr>
    <tr>
      <th>Fold</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2.003391</td>
      <td>0.072061</td>
      <td>0.957225</td>
      <td>0.962070</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.636676</td>
      <td>0.075003</td>
      <td>0.966533</td>
      <td>0.959000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.591288</td>
      <td>0.073190</td>
      <td>0.956435</td>
      <td>0.962686</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.955630</td>
      <td>0.071822</td>
      <td>0.954774</td>
      <td>0.962465</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.587307</td>
      <td>0.078099</td>
      <td>0.968069</td>
      <td>0.966275</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="validate-results-randon-forest-classifier" class="level2">
<h2 class="anchored" data-anchor-id="validate-results-randon-forest-classifier">Validate results: Randon Forest Classifier</h2>
<p>The classification model with the best results was the Random Forest Classifier, with <strong>F-beta = 0.811</strong> using the <strong>Test dataset</strong>. According to the results, 6 out of 7 bot accounts were properly classified, and 826 human accounts out of 829.</p>
<p>Next step is to validate the chosen classifier with the <strong>Validation dataset</strong>.</p>
<div class="cell" data-execution_count="27">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1"></a>X_val_git <span class="op">=</span> preprocess_git_df(X_val_git_og)</span>
<span id="cb29-2"><a href="#cb29-2"></a></span>
<span id="cb29-3"><a href="#cb29-3"></a>y_pred_rf_adj_val <span class="op">=</span> rf_adj.predict(X_val_git)</span>
<span id="cb29-4"><a href="#cb29-4"></a></span>
<span id="cb29-5"><a href="#cb29-5"></a>precision, recall, f2_score <span class="op">=</span> print_model_report(rf_adj, X_train_git_SMOTE, y_train_git_SMOTE, X_val_git, y_val_git)</span>
<span id="cb29-6"><a href="#cb29-6"></a>results <span class="op">=</span> [precision, recall, f2_score]</span>
<span id="cb29-7"><a href="#cb29-7"></a>df_scores <span class="op">=</span> add_score_to_df(df_scores, <span class="st">'Random Forest'</span>, <span class="st">'Validation'</span>, results)</span>
<span id="cb29-8"><a href="#cb29-8"></a></span>
<span id="cb29-9"><a href="#cb29-9"></a><span class="co"># Show prettified results</span></span>
<span id="cb29-10"><a href="#cb29-10"></a>score_dict <span class="op">=</span> {<span class="st">'Score'</span>:{<span class="st">'Precision'</span>: precision,</span>
<span id="cb29-11"><a href="#cb29-11"></a>                       <span class="st">'Recall'</span>: recall,</span>
<span id="cb29-12"><a href="#cb29-12"></a>                       <span class="st">'F2-score'</span>: f2_score}}</span>
<span id="cb29-13"><a href="#cb29-13"></a>pd.DataFrame.from_dict(score_dict)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display" data-execution_count="27">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>F2-score</th>
      <td>0.600</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.333</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.750</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="precision-recall-curve-5" class="level4">
<h4 class="anchored" data-anchor-id="precision-recall-curve-5">Precision-Recall Curve</h4>
<div class="cell" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a>plt.figure()</span>
<span id="cb30-2"><a href="#cb30-2"></a>plt.title(<span class="st">"Precision-Recall Curve - Validation - Random Forest"</span>, fontsize<span class="op">=</span><span class="dv">18</span>)</span>
<span id="cb30-3"><a href="#cb30-3"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb30-4"><a href="#cb30-4"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb30-5"><a href="#cb30-5"></a></span>
<span id="cb30-6"><a href="#cb30-6"></a>visualizer <span class="op">=</span> PrecisionRecallCurve(rf_adj, classes<span class="op">=</span>[<span class="st">"Human"</span>, <span class="st">"Bot"</span>])</span>
<span id="cb30-7"><a href="#cb30-7"></a>visualizer.fit(X_train_git_SMOTE, y_train_git_SMOTE)</span>
<span id="cb30-8"><a href="#cb30-8"></a>visualizer.score(X_val_git, y_val_git)</span>
<span id="cb30-9"><a href="#cb30-9"></a></span>
<span id="cb30-10"><a href="#cb30-10"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="feature-importance-1" class="level4">
<h4 class="anchored" data-anchor-id="feature-importance-1">Feature importance</h4>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a>viz <span class="op">=</span> FeatureImportances(rf_adj, xlabel<span class="op">=</span><span class="st">'Relative importance (coefficient)'</span>, relative<span class="op">=</span><span class="va">False</span>, colormap<span class="op">=</span><span class="st">'yellowbrick'</span>)</span>
<span id="cb31-2"><a href="#cb31-2"></a>viz.fit(X_val_git, y_val_git)</span>
<span id="cb31-3"><a href="#cb31-3"></a>viz.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="classifiers_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>When trying these results with the <strong>Validation dataset</strong>, the obtained score was <strong>F-beta = 0.6</strong>. Given that there were only 4 occurrences of bot accounts, three of them were classified correctly and only one was not. Regarding the human accounts, 493 out of 499 accounts were classified accurately.</p>
<p>Looking at the feature importances obtained from our chosen classifier, it is clear that the terms score variable we produced was the most relevant for deciding the classes, followed by the logarithmic transformation of the interquartilic range of the number of words in the commit messages, with a relative importance of 60%. Then, the logarithmic transformation of the median number of files and the number of commits have a relative importance of around 20%, while the rest of the variables are barely significant for the classification.</p>
<div class="cell" data-execution_count="30">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="op">%%</span>javascript</span>
<span id="cb32-2"><a href="#cb32-2"></a> IPython.OutputArea.prototype._should_scroll <span class="op">=</span> function(lines) {</span>
<span id="cb32-3"><a href="#cb32-3"></a>     <span class="cf">return</span> false<span class="op">;</span></span>
<span id="cb32-4"><a href="#cb32-4"></a> }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<script type="application/javascript">
 IPython.OutputArea.prototype._should_scroll = function(lines) {
     return false;
 }

</script>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button,
        { trigger: "manual",
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        }
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config);
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="classifiers_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>
